# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000, 9) *(включая `sample_id`; признаков для кластеризации: 8)*
- Признаки: числовые
- Пропуски: нет 
- "Подлости" датасета: разные шкалы, много шума

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000, 4) *(включая `sample_id`; признаков: 3)*
- Признаки: числовые
- Пропуски: нет 
- "Подлости" датасета: выбросы, много шума

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (15000, 4) *(включая `sample_id`; признаков: 3)*
- Признаки: числовые
- Пропуски: нет 
- "Подлости" датасета: разная плотность, много шума

### 1.4 Dataset D

- Файл: `S07-hw-dataset-04.csv`
- Размер: (10000, 33) *(включая `sample_id`; признаков: 32)*
- Признаки: числовые и категориальные
- Пропуски: есть во всех числовых признаках, порядка 200 строк в каждом 
- "Подлости" датасета:  высокая размерность, есть категориальные 

## 2. Protocol

- Препроцессинг:
  -  исключение `sample_id` из признаков.
  -  Для числовых признаков: `SimpleImputer(strategy="median")` + `StandardScaler()`.
  -  Для категориальных: `SimpleImputer(strategy="most_frequent")` + `OneHotEncoder(handle_unknown="ignore")`.

- Поиск гиперпараметров:
  - диапозон `k` для поиска KMeans - `[2; 20]` 
  - сетка для DBSCAN `eps` [0.001; 2.0]/`min_samples` (3, 5, 10, 15)
  - лучший алгоритм отбирался по наибольшему `silhouette` 
- Метрики: silhouette, Davies-Bouldin, Calinski-Harabasz, для DBSCAN считались без учета шумовых точек
- Визуализация: PCA(2D), silhouette vs k, silhouette vs eps

## 3. Models

На каждом датасете сравнивались следующие модели и подбирались соответствтующие параметры:

- KMeans (`k`, фиксировались `random_state`, `n_init`)
- DBSCAN (`eps`, `min_samples`, подсчитывалась доля шума),

## 4. Results

### 4.1 Dataset A

- Лучший метод и параметры: `KMeans`, `k = 2`
- Метрики (silhouette / DB / CH): `0.5220`, `0.6850`, `11786.9550`
- Если был DBSCAN: доля шума и комментарий
- KMeans показал лучшие метрики

### 4.2 Dataset B

- Лучший метод и параметры: `DBSCAN`, `eps = 1.0`, `min_samples = 15`
- Метрики (silhouette / DB / CH): отсутствуют, единственный кластер
- DBSCAN лучше справляется с нелинейными данными, разбиение KMeans визуально не интерпретируемо

### 4.3 Dataset C

- Лучший метод и параметры: `KMeans`, `k = 3`
- Метрики (silhouette / DB / CH): `0.3160`, `1.1580`, `6957.1630`
- KMeans разбил данные лучше, чем DBSCAN, несмотря на различную плотность в данных

### 4.4 Dataset D

- Лучший метод и параметры: `KMeans`, `k = 5`
- Метрики (silhouette / DB / CH): `0.4550`, `0.9520`, `5323.5000`
- KMeans показал лучшие метрики и лучшую визуальную интерпретируемость PCА(2D)

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

KMeans плохо показывает себя при работе с несферическими кластерами (хуже работают центроиды), с кластерами разной плотности (KMeans ищет центры, а не плотности), с выбросами и шумами (не может их отсеять). С подобными данными лучше работает DBSCAN, он собирает кластеры по соседям, а не подбирает центры, и помечает выбросы как отдельный класс.
На результат работы обоих алгоритмов сильно влияло масштабирование и пропуски. DBSCAN лучше справлялся с неоднородными данными и выбросами.

### 5.2 Устойчивость (обязательно для одного датасета)

Для проверки устойчивости были сделаны 5 запусков KMeans по разным seed. При заранее вычисленном оптимальном значении k для заданного датасета результаты работы алгоритма абсолютно не отличаются друг от друга, поэтому можно считать результаты устойчивыми.

### 5.3 Интерпретация кластеров

- сравнение mean/std признаков в кластерах

- визуализация через PCA для проверки разделимости

KMeans нашёл устойчивые кластеры (ARI ~1.0). Качество силуэтом > 0.7 - хорошее разделение. Кластеры разного размера (в лучшем случае 30%/40%/30%). Масштабирование критично для качества.

## 6. Conclusion

KMeans — для сферических кластеров, требует K, чувствителен к выбросам и масштабированию, использует n_init для устойчивости

DBSCAN — для произвольных форм, сам определяет число кластеров, выделяет шум (-1), требует подбора eps и min_samples

Метрики качества:

    Silhouette (-1 до 1) — насколько точки близки к своим кластерам

    Davies-Bouldin (меньше = лучше) — отношение внутри/между кластерами

    Calinski-Harabasz (больше = лучше) — отношение дисперсий между/внутри

PCA 2D — для визуализации, показывает объяснённую дисперсию

Протокол эксперимента:

    Препроцессинг (масштабирование, обработка пропусков)

    Подбор гиперпараметров (грид-серч с метриками)

    Оценка устойчивости (ARI между запусками)

    Интерпретация результатов (профили кластеров)